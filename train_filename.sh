CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img -c config/coco_img.py --datasets config/coco_img.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_finetune/test -c config/coco_img.py --datasets config/coco_img.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased
# CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./attribution_finetune/test -c config/test_finetune_img.py --datasets config/test_train_img.json --resume attribution_finetune/new_all_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
# train from scratch
CUDA_VISIBLE_DEVICES=0 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/ranking_scratch -c config/train_ranking_img.py --datasets config/coco_img.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased
# train with pretrained model
CUDA_VISIBLE_DEVICES=1 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/ranking_finetune -c config/train_ranking_img.py --datasets config/coco_img.json --pretrain_model_path attribution_img/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
## test with test set
CUDA_VISIBLE_DEVICES=0 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/best_test_0/ranking_scratch -c config/train_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/ranking_scratch/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/best_test_0/ranking_finetune -c config/train_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/ranking_finetune/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/test_0004/ranking_scratch -c config/train_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/ranking_scratch/checkpoint0004.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/test_0004/ranking_finetune -c config/train_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/ranking_finetune/checkpoint0004.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/test_0009/ranking_scratch -c config/train_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/ranking_scratch/checkpoint0009.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/test_0009/ranking_finetune -c config/train_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/ranking_finetune/checkpoint0009.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/best_test_1/ranking_scratch -c config/train_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/ranking_scratch/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/best_test_1/ranking_finetune -c config/train_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/ranking_finetune/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased

CUDA_VISIBLE_DEVICES=0 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/test_0014/ranking_scratch -c config/train_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/ranking_scratch/checkpoint0014.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/test_0014/ranking_finetune -c config/train_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/ranking_finetune/checkpoint0014.pth --options text_encoder_type=checkpoints/bert-base-uncased

CUDA_VISIBLE_DEVICES=0 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/test_0019/ranking_scratch -c config/train_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/ranking_scratch/checkpoint0019.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u train_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/test_0019/ranking_finetune -c config/train_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/ranking_finetune/checkpoint0019.pth --options text_encoder_type=checkpoints/bert-base-uncased
## use hard negatives from training to train ???

## finetune only linear layers with DR Loss
CUDA_VISIBLE_DEVICES=0 python -u finetune_ranking.py --save_results --output_dir ./attribution_finetune/adapter_rank/all_loss --use_reg_loss -c config/finetune_ranking_img.py --datasets config/coco_img.json --pretrain_model_path attribution_img/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune_ranking.py --save_results --output_dir ./attribution_finetune/adapter_rank/const_loss -c config/finetune_ranking_img.py --datasets config/coco_img.json --pretrain_model_path attribution_img/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased

CUDA_VISIBLE_DEVICES=0 python -u finetune_ranking.py --save_results --output_dir ./attribution_finetune/adapter_rank_bs4/all_loss --use_reg_loss -c config/finetune_ranking_img.py --datasets config/coco_img.json --pretrain_model_path attribution_img/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune_ranking.py --save_results --output_dir ./attribution_finetune/adapter_rank_bs4/const_loss -c config/finetune_ranking_img.py --datasets config/coco_img.json --pretrain_model_path attribution_img/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased

## test adapter # AttributionGD/attribution_finetune/adapter_rank/all_loss/checkpoint_best_regular.pth
CUDA_VISIBLE_DEVICES=0 python -u finetune_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/adapter_rank/all_loss_0009 -c config/finetune_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/adapter_rank/all_loss/checkpoint0009.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/adapter_rank/const_loss_0009 -c config/finetune_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/adapter_rank/const_loss/checkpoint0009.pth --options text_encoder_type=checkpoints/bert-base-uncased

CUDA_VISIBLE_DEVICES=0 python -u finetune_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/adapter_rank_bs4/all_loss_0019 -c config/finetune_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/adapter_rank_bs4/all_loss/checkpoint0019.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune_ranking.py --save_results --output_dir ./attribution_finetune/sum_test_ranking/adapter_rank_bs4/const_loss_0019 -c config/finetune_ranking_img.py --eval --datasets config/coco_img.json --resume attribution_finetune/adapter_rank_bs4/const_loss/checkpoint0019.pth --options text_encoder_type=checkpoints/bert-base-uncased

## test initial model with new DR_Loss
CUDA_VISIBLE_DEVICES=1 python -u finetune_ranking.py --save_results --output_dir ./attribution_finetune/adapter_rank_test/const_loss -c config/finetune_ranking_img.py --datasets config/coco_img.json --pretrain_model_path attribution_img/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased

## train with different backbones AttributionGD/checkpoints/groundingdino_swinb_cogcoor.pth
# CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_swinT -c config/coco_img.py --datasets config/coco_img.json --pretrain_model_path checkpoints/groundingdino_swinb_cogcoor.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_swinT/same_cf -c config/coco_img_swinT.py --datasets config/coco_img.json --pretrain_model_path checkpoints/groundingdino_swint_ogc.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u main.py --save_results --output_dir ./attribution_img_swinT/original_cf -c config/coco_img_swinT.py --datasets config/coco_img.json --pretrain_model_path checkpoints/groundingdino_swint_ogc.pth --options text_encoder_type=checkpoints/bert-base-uncased

## test for swinT trained with positives # AttributionGD/attribution_img_swinT/same_cf/checkpoint_best_regular.pth
CUDA_VISIBLE_DEVICES=1 python -u main.py --save_results --output_dir ./attribution_img_swinT/test_trained_model_pos/same_cf/best_test -c config/coco_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/same_cf/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u main.py --save_results --output_dir ./attribution_img_swinT/test_trained_model_pos/same_cf/newest_test -c config/coco_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/same_cf/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u main.py --save_results --output_dir ./attribution_img_swinT/test_trained_model_pos/same_cf/test_0014 -c config/coco_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/same_cf/checkpoint0014.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u main.py --save_results --output_dir ./attribution_img_swinT/test_trained_model_pos/same_cf/test_0019 -c config/coco_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/same_cf/checkpoint0019.pth --options text_encoder_type=checkpoints/bert-base-uncased
# AttributionGD/attribution_img_swinT/original_cf/checkpoint_best_regular.pth
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_swinT/test_trained_model_pos/original_cf/best_test -c config/coco_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/original_cf/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_swinT/test_trained_model_pos/original_cf/newest_test -c config/coco_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/original_cf/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_swinT/test_trained_model_pos/original_cf/test_0014 -c config/coco_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/original_cf/checkpoint0014.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_swinT/test_trained_model_pos/original_cf/test_0019 -c config/coco_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/original_cf/checkpoint0019.pth --options text_encoder_type=checkpoints/bert-base-uncased

## run swinB from scratch # AttributionGD/checkpoints/groundingdino_swinb_cogcoor.pth
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_swinB/same_cf -c config/coco_img.py --datasets config/coco_img.json --pretrain_model_path checkpoints/groundingdino_swinb_cogcoor.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u main.py --save_results --output_dir ./attribution_img_swinB/original_cf -c config/coco_img_swinB.py --datasets config/coco_img.json --pretrain_model_path checkpoints/groundingdino_swinb_cogcoor.pth --options text_encoder_type=checkpoints/bert-base-uncased

## test for swinB trained with positives # AttributionGD/attribution_img_swinB/same_cf/checkpoint_best_regular.pth
CUDA_VISIBLE_DEVICES=1 python -u main.py --save_results --output_dir ./attribution_img_swinB/test_trained_model_pos/same_cf/best_test -c config/coco_img.py --eval --datasets config/coco_img.json --resume attribution_img_swinB/same_cf/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u main.py --save_results --output_dir ./attribution_img_swinB/test_trained_model_pos/same_cf/newest_test -c config/coco_img.py --eval --datasets config/coco_img.json --resume attribution_img_swinB/same_cf/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_swinB/test_trained_model_pos/same_cf/test_0014 -c config/coco_img.py --eval --datasets config/coco_img.json --resume attribution_img_swinB/same_cf/checkpoint0014.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u main.py --save_results --output_dir ./attribution_img_swinB/test_trained_model_pos/same_cf/test_0019 -c config/coco_img.py --eval --datasets config/coco_img.json --resume attribution_img_swinB/same_cf/checkpoint0019.pth --options text_encoder_type=checkpoints/bert-base-uncased
# AttributionGD/attribution_img_swinB/original_cf/checkpoint_best_regular.pth
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_swinB/test_trained_model_pos/original_cf/best_test -c config/coco_img_swinB.py --eval --datasets config/coco_img.json --resume attribution_img_swinB/original_cf/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_swinB/test_trained_model_pos/original_cf/newest_test -c config/coco_img_swinB.py --eval --datasets config/coco_img.json --resume attribution_img_swinB/original_cf/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased
# CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_swinB/test_trained_model_pos/original_cf/test_0014 -c config/coco_img_swinB.py --eval --datasets config/coco_img.json --resume attribution_img_swinB/original_cf/checkpoint0014.pth --options text_encoder_type=checkpoints/bert-base-uncased
# CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_swinB/test_trained_model_pos/original_cf/test_0019 -c config/coco_img_swinB.py --eval --datasets config/coco_img.json --resume attribution_img_swinB/original_cf/checkpoint0019.pth --options text_encoder_type=checkpoints/bert-base-uncased

## finetune swinT with negatives # AttributionGD/attribution_img_swinT/original_cf/checkpoint_best_regular.pth
CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/finetune/all_loss --use_reg_loss -c config/finetune_img_swinT.py --datasets config/coco_img.json --pretrain_model_path attribution_img_swinT/original_cf/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/finetune/const_loss -c config/finetune_img_swinT.py --datasets config/coco_img.json --pretrain_model_path attribution_img_swinT/original_cf/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased

CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/finetune_samecf/all_loss --use_reg_loss -c config/finetune_img_swinT.py --datasets config/coco_img.json --pretrain_model_path attribution_img_swinT/original_cf/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/finetune_samecf/const_loss -c config/finetune_img_swinT.py --datasets config/coco_img.json --pretrain_model_path attribution_img_swinT/original_cf/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased

## test finetuned model
CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_model/all_loss/best_first015 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune/all_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_model/const_loss/best_first015 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune/const_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_model/all_loss/test_0014 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune/all_loss/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_model/const_loss/test_0014 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune/const_loss/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased

CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_model/all_loss/best_0030 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune/all_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_model/const_loss/best_0030 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune/const_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_model/all_loss/test_0029 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune/all_loss/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_model/const_loss/test_0029 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune/const_loss/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased
## test finetuned swinT with same config as swinB # ./attribution_img_swinT/finetune_samecf/all_loss
CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_samecf/all_loss/best_first0009 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune_samecf/all_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_samecf/const_loss/best_first0009 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune_samecf/const_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_samecf/all_loss/test_0009 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune_samecf/all_loss/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_samecf/const_loss/test_0009 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune_samecf/const_loss/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased

# CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_samecf/all_loss/best_first0017 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune_samecf/all_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_samecf/const_loss/best_first0017 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune_samecf/const_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
# CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_samecf/all_loss/test_0017 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune_samecf/all_loss/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_samecf/const_loss/test_0017 -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune_samecf/const_loss/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased

CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_samecf/all_loss/best_all -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune_samecf/all_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_samecf/const_loss/best_all -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune_samecf/const_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_samecf/all_loss/newest_all -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune_samecf/all_loss/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./attribution_img_swinT/test_finetuned_samecf/const_loss/newest_all -c config/finetune_img_swinT.py --eval --datasets config/coco_img.json --resume attribution_img_swinT/finetune_samecf/const_loss/checkpoint.pth --options text_encoder_type=checkpoints/bert-base-uncased

### train with swinB + BERT-large
CUDA_VISIBLE_DEVICES=0 python -u main_BERT.py --save_results --output_dir ./attribution_img_BERTlarge -c config/coco_img_BERTlarge.py --datasets config/coco_img.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-large-uncased
CUDA_VISIBLE_DEVICES=1 python -u main_BERT.py --save_results --output_dir ./attribution_img_BERTlarge/conf1 -c config/coco_img_BERTlarge_conf1.py --datasets config/coco_img.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-large-uncased
CUDA_VISIBLE_DEVICES=1 python -u main_BERT.py --save_results --output_dir ./attribution_img_BERTlarge/conf2 -c config/coco_img_BERTlarge_conf2.py --datasets config/coco_img.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-large-uncased
CUDA_VISIBLE_DEVICES=0 python -u main_BERT.py --save_results --output_dir ./attribution_img_BERTlarge/conf3 -c config/coco_img_BERTlarge_conf3.py --datasets config/coco_img.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-large-uncased

### test swinB + BERT-large
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_BERTlarge/test_trained_model_pos/best_test -c config/coco_img_BERTlarge.py --eval --datasets config/coco_img.json --resume attribution_img_BERTlarge/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-large-uncased
CUDA_VISIBLE_DEVICES=1 python -u main.py --save_results --output_dir ./attribution_img_BERTlarge/test_trained_model_pos/newest_test -c config/coco_img_BERTlarge.py --eval --datasets config/coco_img.json --resume attribution_img_BERTlarge/checkpoint.pth --options text_encoder_type=checkpoints/bert-large-uncased
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_BERTlarge/test_trained_model_pos/test_0019 -c config/coco_img_BERTlarge.py --eval --datasets config/coco_img.json --resume attribution_img_BERTlarge/checkpoint0019.pth --options text_encoder_type=checkpoints/bert-large-uncased
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_BERTlarge/conf1/test_0023 -c config/coco_img_BERTlarge_conf1.py --eval --datasets config/coco_img.json --resume attribution_img_BERTlarge/conf1/checkpoint.pth --options text_encoder_type=checkpoints/bert-large-uncased
CUDA_VISIBLE_DEVICES=1 python -u main.py --save_results --output_dir ./attribution_img_BERTlarge/conf2/best_test -c config/coco_img_BERTlarge_conf2.py --eval --datasets config/coco_img.json --resume attribution_img_BERTlarge/conf2/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-large-uncased
CUDA_VISIBLE_DEVICES=0 python -u main.py --save_results --output_dir ./attribution_img_BERTlarge/conf3/best_test -c config/coco_img_BERTlarge_conf3.py --eval --datasets config/coco_img.json --resume attribution_img_BERTlarge/conf3/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-large-uncased

### finetune BERT-large
CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./aattribution_img_BERTlarge/finetune_best/all_loss --use_reg_loss -c config/finetune_img_BERTlarge.py --datasets config/coco_img.json --pretrain_model_path attribution_img_BERTlarge/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-large-uncased
CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./aattribution_img_BERTlarge/finetune_best/const_loss -c config/finetune_img_BERTlarge.py --datasets config/coco_img.json --pretrain_model_path attribution_img_BERTlarge/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-large-uncased
### test finetuned BERT-large
CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./aattribution_img_BERTlarge/test_finetuned_all/best_20 -c config/finetune_img_BERTlarge.py --eval --datasets config/coco_img.json --resume aattribution_img_BERTlarge/finetune_best/all_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-large-uncased
# CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./aattribution_img_BERTlarge/test_finetuned_all/newest_20 -c config/finetune_img_BERTlarge.py --eval --datasets config/coco_img.json --resume aattribution_img_BERTlarge/finetune_best/all_loss/checkpoint.pth --options text_encoder_type=checkpoints/bert-large-uncased

CUDA_VISIBLE_DEVICES=1 python -u finetune.py --save_results --output_dir ./aattribution_img_BERTlarge/test_finetuned_const/best_20 -c config/finetune_img_BERTlarge.py --eval --datasets config/coco_img.json --resume aattribution_img_BERTlarge/finetune_best/const_loss/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-large-uncased
# CUDA_VISIBLE_DEVICES=0 python -u finetune.py --save_results --output_dir ./aattribution_img_BERTlarge/test_finetuned_const/newest_20 -c config/finetune_img_BERTlarge.py --eval --datasets config/coco_img.json --resume aattribution_img_BERTlarge/finetune_best/const_loss/checkpoint.pth --options text_encoder_type=checkpoints/bert-large-uncased